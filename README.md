the paper instead of including LaTeX files.

# RL-Hasse-Clustering

This repository contains the code and data for our paper:  
**‚ÄúFrom Reinforcement Learning Trajectories to Strategy Posets: Hasse-based Clustering of Dependency Matrices.‚Äù**  
üìÑ [Read the paper here](https://link-to-your-paper.com)  

We introduce a full pipeline that goes from reinforcement learning trajectories in custom puzzle environments to interpretable procedural strategies using a novel **Hasse diagram‚Äìbased clustering algorithm**. We compare this to standard unsupervised learning (DBSCAN, hierarchical clustering) and test robustness under controlled data corruption.

---

## üöÄ Overview

**Pipeline at a glance:**

1. **Custom Puzzle Games**  
   - *Game v2*: one solution (explosive ‚Üí rock ‚Üí key ‚Üí door).  
   - *Game v3*: two solutions (door path or treasure path).  

2. **Reinforcement Learning**  
   - PPO (Stable-Baselines3) with reward shaping + curriculum.  

3. **Data Mining**  
   - Clean logs ‚Üí symbolic event codes ‚Üí infinity-ratio analysis.  

4. **Dependency Matrices**  
   - Per winning episode, capture temporal relations among key events.  

5. **Clustering & Analysis**  
   - **Hasse-based clustering (ours)**: consensus + high coverage combinations.  
   - **Baselines**: DBSCAN, hierarchical clustering.  
   - Robustness: format-preserving corruption of 10% episodes.  

6. **Findings**  
   - Hasse clustering is more accurate and robust: recovers true strategies even with corruption.  
   - Distance-based methods fragment into noisy clusters or drift.  

---

## üìÇ Repository Layout

```plaintext
game-rl-hasse/
‚îú‚îÄ README.md
‚îú‚îÄ .gitignore
‚îú‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ game/                   # Environments, assets, utils
‚îÇ  ‚îú‚îÄ v2/                  # Game v2 env + reward shaping
‚îÇ  ‚îî‚îÄ v3/                  # Game v3 env + reward shaping
‚îÇ
‚îú‚îÄ training/               # PPO training + checkpoints
‚îÇ  ‚îú‚îÄ train_ppo.py
‚îÇ  ‚îú‚îÄ continue_training.py
‚îÇ  ‚îú‚îÄ eval_policy.py
‚îÇ  ‚îî‚îÄ checkpoints/
‚îÇ     ‚îú‚îÄ v2/
‚îÇ     ‚îî‚îÄ v3/
‚îÇ
‚îú‚îÄ data/                   # Raw + processed logs
‚îÇ  ‚îú‚îÄ v2/
‚îÇ  ‚îÇ  ‚îú‚îÄ raw/
‚îÇ  ‚îÇ  ‚îú‚îÄ processed/
‚îÇ  ‚îÇ  ‚îî‚îÄ corrupted/
‚îÇ  ‚îî‚îÄ v3/
‚îÇ     ‚îú‚îÄ raw/
‚îÇ     ‚îú‚îÄ processed/
‚îÇ     ‚îî‚îÄ corrupted/
‚îÇ
‚îú‚îÄ preprocessing/          # Cleaning logs, seqOfSets, corruption
‚îÇ  ‚îú‚îÄ seq_of_sets.py
‚îÇ  ‚îú‚îÄ corrupt_data.py
‚îÇ  ‚îú‚îÄ sort_by_outcome.py
‚îÇ  ‚îî‚îÄ notebooks/
‚îÇ     ‚îú‚îÄ removeTheMove.ipynb
‚îÇ     ‚îú‚îÄ removeTheSelectItem.ipynb
‚îÇ     ‚îú‚îÄ filterFailedInteractions.ipynb
‚îÇ     ‚îî‚îÄ corruptData.ipynb
‚îÇ
‚îú‚îÄ dependency_matrices/    # Build M_c matrices
‚îÇ  ‚îú‚îÄ new_alg_v4.py
‚îÇ  ‚îú‚îÄ outputs/
‚îÇ  ‚îÇ  ‚îú‚îÄ v2/
‚îÇ  ‚îÇ  ‚îî‚îÄ v3/
‚îÇ  ‚îî‚îÄ notebooks/
‚îÇ     ‚îî‚îÄ newAlgV4_demo.ipynb
‚îÇ
‚îú‚îÄ clustering/             # Clustering algorithms
‚îÇ  ‚îú‚îÄ hasse/
‚îÇ  ‚îÇ  ‚îú‚îÄ hasse_clustering.py
‚îÇ  ‚îÇ  ‚îú‚îÄ consensus_and_coverage.py
‚îÇ  ‚îÇ  ‚îî‚îÄ figures/
‚îÇ  ‚îú‚îÄ dbscan_clustering.py
‚îÇ  ‚îú‚îÄ hierarchical_clustering.py
‚îÇ  ‚îú‚îÄ custom_graph_clustering.py
‚îÇ  ‚îî‚îÄ outputs/
‚îÇ     ‚îú‚îÄ v2/
‚îÇ     ‚îî‚îÄ v3/
‚îÇ
‚îú‚îÄ figures/                # Screenshots + clustering figures
‚îÇ  ‚îú‚îÄ v2/
‚îÇ  ‚îî‚îÄ v3/
‚îÇ
‚îî‚îÄ paper_link.txt          # Link to the published paper



> Note: *Game v2 with move* is intentionally excluded.

---

## ‚öôÔ∏è Requirements

- Python 3.10+  
- [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3)  
- [Gym / Gymnasium](https://gymnasium.farama.org/)  
- Pygame, pytmx (map rendering)  
- Numpy, Pandas, Scipy  
- Scikit-learn (DBSCAN, hierarchical)  
- NetworkX (graph + Hasse analysis)  
- Matplotlib  

Install dependencies with:

```bash
pip install -r requirements.txt
```
‚ñ∂Ô∏è Quick Start
1. Train PPO agent
# Train Game v2
```bash
python training/train_ppo.py --env v2 --timesteps 5000000
```
# Train Game v3
```bash
python training/train_ppo.py --env v3 --timesteps 5000000
```
2. Preprocess logs
```bash
python preprocessing/seq_of_sets.py \
  --input data/v2/raw/final_run.json \
  --output data/v2/processed/sequence_of_sets_formatted.csv
```
4. Build dependency matrices
```bash
python dependency_matrices/new_alg_v4.py \
  --input data/v2/processed/sequence_of_sets_formatted_won.csv \
  --output dependency_matrices/outputs/v2/M_c_matrices_game_won.json
```
6. Run clustering
# Hasse clustering (ours)
```bash
python clustering/hasse/hasse_clustering.py --env v2
```
# DBSCAN
```bash
python clustering/dbscan_clustering.py --env v2 --eps 2.0
```
# Hierarchical
```bash
python clustering/hierarchical_clustering.py --env v2 --threshold 2.5
```
üìä Results (Summary)

Game v2: Hasse finds one consensus strategy (door). DBSCAN/hierarchical split into noisy sub-variants.

Game v3: Hasse separates both winning strategies (door + treasure). DBSCAN/hierarchical show variants but mis-handle incidental pickups.

Robustness: With 10% corrupted sequences, Hasse consensus unchanged. Distance-based methods fragment or degenerate.
